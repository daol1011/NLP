{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79a3caf2-5b7b-4c21-a4bd-82296a3f89e1",
   "metadata": {
    "id": "79a3caf2-5b7b-4c21-a4bd-82296a3f89e1"
   },
   "source": [
    "## Natural Language Processing - Summer Term 2024\n",
    "### Hochschule Karlsruhe\n",
    "### Lecturer: Prof. Dr. Jannik Strötgen\n",
    "### Tutor: Paul Löhr\n",
    "\n",
    "### Students:\n",
    "### Yannick Walla (73005),\n",
    "### Andreas Muth (66357),\n",
    "### Vitali Reinhardt (72578),\n",
    "### Moritz Wolf (91057)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef64b269-6b17-4409-b907-50010c0cc1f8",
   "metadata": {
    "id": "ef64b269-6b17-4409-b907-50010c0cc1f8"
   },
   "source": [
    "# Exercise 05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87ea437-6493-4082-8e93-10e6a6dc42a3",
   "metadata": {
    "id": "e87ea437-6493-4082-8e93-10e6a6dc42a3"
   },
   "source": [
    "- NLP Recap\n",
    "- Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75102490-f8ec-4855-ad83-4a6162158df6",
   "metadata": {
    "id": "75102490-f8ec-4855-ad83-4a6162158df6"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83419e06-965f-4c2e-8af4-ab46b22082ad",
   "metadata": {
    "id": "83419e06-965f-4c2e-8af4-ab46b22082ad",
    "tags": []
   },
   "source": [
    "## Task 1 - NLP Recap:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacc5eee-4940-4d59-b348-3c07894c3e43",
   "metadata": {
    "id": "dacc5eee-4940-4d59-b348-3c07894c3e43",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Q & A\n",
    "\n",
    "Give answers to the following question. If you like, you can treat it as exam preparation, e.g., first try to solve the question without help of the slides ;) But you are obviously allowed to use the slides at any time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a23d949-adfa-4661-92d4-45a2c809dabe",
   "metadata": {
    "id": "1a23d949-adfa-4661-92d4-45a2c809dabe"
   },
   "source": [
    "(1) Name three reasons why natural language processing (NLP) is challenging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f12b01-aebd-47d2-8dcd-1d7572f16994",
   "metadata": {
    "id": "e3f12b01-aebd-47d2-8dcd-1d7572f16994"
   },
   "source": [
    "**Ambiguities**:\n",
    "- **Syntactic Ambiguity**: The exact same sentence can have multiple meanings\n",
    "- **Anaphora Resolution**: It can sometimes be impossible to cleary identify which noun a pronoun refers to\n",
    "- **Interpretation & World Knowledge**: Often understanding a sentence relies on unspoken context and common knowledge.\n",
    "\n",
    "=> Having access to & understanding the right context helps with many ambiguities\n",
    "\n",
    "\n",
    "\n",
    "(VL 1a p.30-34)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29973e60-6435-4c53-b747-98def175474d",
   "metadata": {
    "id": "29973e60-6435-4c53-b747-98def175474d"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5293e25-64b5-4734-b327-4e52eaeb9a03",
   "metadata": {
    "id": "e5293e25-64b5-4734-b327-4e52eaeb9a03"
   },
   "source": [
    "(2) What is tokenization?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284270d5-050f-472d-978d-016332844392",
   "metadata": {
    "id": "284270d5-050f-472d-978d-016332844392"
   },
   "source": [
    "- **Token**: The occurence of a word in a text\n",
    "- **Tokenization**: Segmentation of an input stream into an ordered sequence of tokens\n",
    "- **Tokenizer**: A system that splits texts into word tokens -> does tokenization\n",
    "\n",
    "- Example sentence: \"John likes Mary and Mary likes John.\"\n",
    "    - Tokens: {\"John\", \"likes\", \"Mary\", \"and\", \"Mary\", \"likes\", \"John\", \".\"}\n",
    "\n",
    "(VL 2 p.58)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e404eed0-0a56-44e5-b84e-f4d440ed8103",
   "metadata": {
    "id": "e404eed0-0a56-44e5-b84e-f4d440ed8103"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e0fa79-7297-4bea-882e-b53c6febd87b",
   "metadata": {
    "id": "96e0fa79-7297-4bea-882e-b53c6febd87b"
   },
   "source": [
    "(3) What is a word stem? Give the stem of the word \"undoes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d1146e-49e2-4a17-8861-21ff91e38441",
   "metadata": {
    "id": "65d1146e-49e2-4a17-8861-21ff91e38441"
   },
   "source": [
    "- Stem: The common part to all inflected words\n",
    "    - Does not have to be a proper word from the dictionary\n",
    "\n",
    "    - => basically cut off at the maximum size that still is identical for word variants\n",
    "\n",
    "- Example: undoes\n",
    "    - Stem: undo (undone/undoing/undoable/undoer)\n",
    "\n",
    "(VL 2 p.46)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bca9d3f-0250-4476-9da7-f3a87644b7c2",
   "metadata": {
    "id": "8bca9d3f-0250-4476-9da7-f3a87644b7c2"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a91ff85-98e0-4438-b64d-3837d007125b",
   "metadata": {
    "id": "0a91ff85-98e0-4438-b64d-3837d007125b"
   },
   "source": [
    "(4) What is a word root? Give the root of the word \"undoes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd241a4f-9d0c-40ca-8671-92c79fd07724",
   "metadata": {
    "id": "bd241a4f-9d0c-40ca-8671-92c79fd07724"
   },
   "source": [
    "- Root: The component of the word that\n",
    "    - is common to a set of derived or inflected forms with all affixes removed\n",
    "    - cannot be split further into meaningful components\n",
    "    - carries the principal portion of meaning of the words\n",
    "    - still not has to be found in the dictionary (-> Lemmatization)\n",
    "\n",
    "- Example: undoes\n",
    "    - Root: do (doing/done/redo/undo)\n",
    "\n",
    "(VL 2 p.46)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb2676d-46ef-4fa1-9cc9-8463893c5f4e",
   "metadata": {
    "id": "7bb2676d-46ef-4fa1-9cc9-8463893c5f4e"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6388d52f-8c70-4dbd-b14a-1071d4844530",
   "metadata": {
    "id": "6388d52f-8c70-4dbd-b14a-1071d4844530",
    "tags": []
   },
   "source": [
    "(5) Why should we typically extract word stems/lemmas before preceding with text analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e76baff-9015-4d87-a4bd-f6102f9ade76",
   "metadata": {
    "id": "9e76baff-9015-4d87-a4bd-f6102f9ade76"
   },
   "source": [
    "- **Reduces Complexity**: Collapsing words into their stems/lemmas simplifies the dataset\n",
    "\n",
    "- **Improves Consistency**: Different forms of a word are treated as a single item, improving the consistency of the analysis\n",
    "\n",
    "- **Saves Resources**: Decreasing the number of unique words the system needs to process\n",
    "\n",
    "- **Enhances Matching**: Improving search queries by being able to match different variants of the same word\n",
    "\n",
    "- **Better Insights**: More accurate statistics from the text data if all variants of a word are aggregated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea83f614-0a02-44f2-aa50-c7736415c2da",
   "metadata": {
    "id": "ea83f614-0a02-44f2-aa50-c7736415c2da"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039984ea-d45c-4e6f-80b6-30db3fc0a974",
   "metadata": {
    "id": "039984ea-d45c-4e6f-80b6-30db3fc0a974"
   },
   "source": [
    "(6) What are stop-words? Why it makes sense to remove stop-words before preceding with text analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5f15e2-b5a7-4e48-af13-7894ad3292a4",
   "metadata": {
    "id": "4e5f15e2-b5a7-4e48-af13-7894ad3292a4"
   },
   "source": [
    "Stop words are common words, like \"the\" and \"and\",  and are  removed before text analysis because they don't add much meaning. Removing them reduces noise in the data by focusing on more meaningful words, it improves efficiency by reducing computational complexity, it enhances the relevance of analyses like classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e254c1-de5d-43ce-bff4-2ef6441d7a96",
   "metadata": {
    "id": "07e254c1-de5d-43ce-bff4-2ef6441d7a96"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527ffeae-89e5-4e94-96f0-9cdcbaaea9b1",
   "metadata": {
    "id": "527ffeae-89e5-4e94-96f0-9cdcbaaea9b1"
   },
   "source": [
    "(7) If you had access to frequency statistics for a language, how could you create a list of stop words?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c90b0bc-3c3b-4c4e-a0be-4e381664b378",
   "metadata": {
    "id": "3c90b0bc-3c3b-4c4e-a0be-4e381664b378"
   },
   "source": [
    "Analyze a large corpus of text data to identify frequently occurring words and set a threshold frequency below which words are considered stop words. Than  filter out any words that might be relevant in certain contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cc843d-f19d-4d27-a477-09c0579ac591",
   "metadata": {
    "id": "21cc843d-f19d-4d27-a477-09c0579ac591"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d477f762-b30d-4577-a108-e9a147dce512",
   "metadata": {
    "id": "d477f762-b30d-4577-a108-e9a147dce512"
   },
   "source": [
    "(8) Name a use-case in which we should NOT remove stop-words prior to text analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7408324-b69e-4c2e-bc61-eaa5bafa746d",
   "metadata": {
    "id": "c7408324-b69e-4c2e-bc61-eaa5bafa746d"
   },
   "source": [
    "Sentiment analysis\n",
    "\n",
    "“I told you that she was not happy”\n",
    "\n",
    "The result would be [‘told’, ‘happy’].\n",
    "\n",
    "Meaning would be positive but it is not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd41039-d642-4c06-9fca-b90cb6a103e5",
   "metadata": {
    "id": "cfd41039-d642-4c06-9fca-b90cb6a103e5"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d434b56d-5a8d-4460-9538-3ca7ad04b040",
   "metadata": {
    "id": "d434b56d-5a8d-4460-9538-3ca7ad04b040"
   },
   "source": [
    "(9) What is part-of-speech (POS) tagging? Why is it useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d01947-0ff5-4b35-92d1-377f5d769605",
   "metadata": {
    "id": "13d01947-0ff5-4b35-92d1-377f5d769605"
   },
   "source": [
    "Part-of-speech (POS) tagging assigns grammatical categories to words in a sentence. POS tagging also disambiguates word meanings in context, improving accuracy in tasks like information retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2442623a-c731-45dd-9371-02de018c16e2",
   "metadata": {
    "id": "2442623a-c731-45dd-9371-02de018c16e2"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf59b70-e18e-4368-b49d-2cd861dcc619",
   "metadata": {
    "id": "aaf59b70-e18e-4368-b49d-2cd861dcc619"
   },
   "source": [
    "(10) Explain how n-gram POS tagging works. What is the limitation of this method?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c013176-2dce-444d-8143-6ba800e06475",
   "metadata": {
    "id": "0c013176-2dce-444d-8143-6ba800e06475"
   },
   "source": [
    "N-gram POS tagging combines n-grams with part-of-speech tagging to assign grammatical categories to words based on their context. It uses a statistical algorithm trained on labeled text data to predict POS tags by considering sequences of words. This approach captures more contextual information, enhancing accuracy, especially for words dependent on surrounding context. However, it faces limitations such as data sparsity due to the exponential increase in unique n-grams, limited context, and challenges in disambiguating words with multiple possible POS tags."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e8f9c3-2523-4b51-a138-cafb85c9f31d",
   "metadata": {
    "id": "10e8f9c3-2523-4b51-a138-cafb85c9f31d"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5764bfa6-7a98-4bbf-b9b2-f0b1e0673635",
   "metadata": {
    "id": "5764bfa6-7a98-4bbf-b9b2-f0b1e0673635"
   },
   "source": [
    "(11) What is parsing? Which two main types of parsing exist?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674c0ce2-5f48-4d7d-b0ac-74bbd3b490de",
   "metadata": {
    "id": "674c0ce2-5f48-4d7d-b0ac-74bbd3b490de"
   },
   "source": [
    "In NLP, parsing is one of the processes by which computers understand human language. Parsing involves breaking down a sentence into smaller pieces and identifying its grammatical structure.  So parsing is the process of analyzing the syntax and deeper structure to get the meaning.\n",
    "\n",
    "There are two main techniques for parsing. These are top-down and bottom-up parsing.\n",
    "In top-down parsing the parser tries to build the parse tree from the root node S down to the leaves. The main problem with this approach is that it explores options that do not lead to a complete parse.\n",
    "\n",
    "The bottom-up approach starts with the words as input and then tries to build a tree from the words up, constantly applying grammatical rules one by one. It goes upwards towards the root. The problem with this method is backtracking. Where it explores a path that does not match the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4184dcd9-a022-427e-ba97-80801c34a512",
   "metadata": {
    "id": "4184dcd9-a022-427e-ba97-80801c34a512"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00630f3-e8e2-4f52-b182-a278e1c59824",
   "metadata": {
    "id": "e00630f3-e8e2-4f52-b182-a278e1c59824"
   },
   "source": [
    "(12) What is the difference between a context-free and a context-sensitive language? What is the difference between a context-free and a regular language?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99cba38-ca36-49a9-9d68-936cd8b5abc3",
   "metadata": {
    "id": "e99cba38-ca36-49a9-9d68-936cd8b5abc3"
   },
   "source": [
    "Type-3 (Regular) are the most restricted, suitable only for simple patterns and sequences.\n",
    "\n",
    "Type-2 (Context-free languages) offer more flexibility without context dependency, suitable for many programming and natural languages.\n",
    "\n",
    "Type-1 (Context-sensitive languages) are the most expressive also capable of describing languages witha  complex context-dependent features.\n",
    "\n",
    "Type 3\n",
    "A → aB or 𝐴 → 𝑎\n",
    "Where: 𝐴,𝐵 are non-terminals and 𝑎 is a terminal. It can contain at most one non-terminal, and if present, it must immediately follow a terminal.\n",
    "\n",
    "Type 2\n",
    "A→γ,\n",
    "where 𝐴 is a non-terminal, and 𝛾 is any sequence of terminals and/or non-terminals (including the empty sequence). They don’t consider the context where a non-terminal is replaced.\n",
    "\n",
    "Type 1\n",
    "αAβ→αγβ, where: 𝐴 is a non-terminal and 𝛼,𝛽,𝛾 any sequence of symbols, including the empty sequence (except that 𝛾 must not be shorter than 𝐴). This ensures that the length of the string does not decrease by doing the application of a rule.\n",
    "Type 1 are more powerful than context free by expressing the languages with intricate dependencies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239765a1-332f-4076-8cc6-e50d1b924a87",
   "metadata": {
    "id": "239765a1-332f-4076-8cc6-e50d1b924a87"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe97a9d2-cf4d-4f9b-abad-f90fa7862a94",
   "metadata": {
    "id": "fe97a9d2-cf4d-4f9b-abad-f90fa7862a94"
   },
   "source": [
    "(13) Give an equivalent grammar in Chomsky Normal form for the Grammar G=(N,T,P,S) with N={S,A,B,C}, T={a,b,c}, P={S->ABC, A->a, B->b, C->c}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0178a8c-fd3b-4f3d-b4e3-7e59afa54d6a",
   "metadata": {
    "id": "f0178a8c-fd3b-4f3d-b4e3-7e59afa54d6a"
   },
   "source": [
    "\n",
    "The Task:\n",
    "N = {S, A, B, C} (non-terminal symbols)\n",
    "\n",
    "T = {a, b, c} (terminal symbols)\n",
    "\n",
    "P = {S -> ABC, A -> a, B -> b, C -> c} (production rules)\n",
    "\n",
    "S is the start symbol\n",
    "\n",
    "\n",
    "We need to convert the Formal Grammars to Chomsky Normal Form. This means to follow the rules from CNF.\n",
    "\n",
    "\n",
    "\n",
    "ABC ist not Valid and we need to change it to:\n",
    "S -> AX\n",
    "X -> BC\n",
    "\n",
    "\n",
    "\n",
    "We do not need to change this part: (A -> a, B -> b, C -> c)\n",
    "\n",
    "N = {S, A, B, C, X} (non-terminal symbols)\n",
    "\n",
    "T = {a, b, c} (terminal symbols)\n",
    "\n",
    "P = {S -> AX, A -> a, B -> b, C -> c, X -> BC} (production rules)\n",
    "\n",
    "S is the start symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f282280c-b3fc-429e-80a7-db9eb79dd9bc",
   "metadata": {
    "id": "f282280c-b3fc-429e-80a7-db9eb79dd9bc"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eb0210-866e-4ce7-85c8-b69f4d08af61",
   "metadata": {
    "id": "c5eb0210-866e-4ce7-85c8-b69f4d08af61"
   },
   "source": [
    "(14) Explain how shift-reduce parsing works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aefc47-64aa-4d8e-af3f-0a5b3694d9d7",
   "metadata": {
    "id": "f9aefc47-64aa-4d8e-af3f-0a5b3694d9d7"
   },
   "source": [
    "The Shift reduce is a bottom up parsing. It works by using a pushdown automaton understand a stack to get the CFL.\n",
    "\n",
    "Do the following two operations\n",
    "\n",
    "SHIFT = Put a word from the Input String to the stack\n",
    "\n",
    "Reduce = Check if the words of the stack match a production rule on the right if yes replace it with the left-hand side.\n",
    "\n",
    "Stop at S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acc8326-c3cf-40e5-ae7f-7e2be18cd961",
   "metadata": {
    "id": "7acc8326-c3cf-40e5-ae7f-7e2be18cd961"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153e9ca5-d3d1-47d4-a305-51569664e56a",
   "metadata": {
    "id": "153e9ca5-d3d1-47d4-a305-51569664e56a"
   },
   "source": [
    "(15) What is the grammar ambiguity problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a94da6a-0175-436c-a7da-3495abe4cdbb",
   "metadata": {
    "id": "8a94da6a-0175-436c-a7da-3495abe4cdbb"
   },
   "source": [
    "Grammar ambiguity\n",
    "\n",
    "The grammar ambiguity problem is the situation where a sentence or string can be parsed in multiple valid ways according to the same grammar, resulting in more than one valid parse or syntactic structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5624e353-90c6-45ac-9a3c-1c6868b50877",
   "metadata": {
    "id": "5624e353-90c6-45ac-9a3c-1c6868b50877"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c674b6-b855-4188-b7d5-8f85ab2bacf0",
   "metadata": {
    "id": "a4c674b6-b855-4188-b7d5-8f85ab2bacf0"
   },
   "source": [
    "## Task 2 - Named Entity Recognition:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450b3c85-077d-4d83-96f1-add9db8a2c44",
   "metadata": {
    "id": "450b3c85-077d-4d83-96f1-add9db8a2c44",
    "tags": []
   },
   "source": [
    "### Part 1: Automated Annotations\n",
    "\n",
    "Use Spacy to annotate entities in the debates dataset (available as part of the JSON in the data directory). [Depending on your computer, the extraction may take some time. Therefore, you are allowed to restrict the size of the text, e.g. to the first 250 sentences. Feel free to use a larger share of data to get better insights.]\n",
    "\n",
    "Tip: Use the en_core_web_sm corpus\n",
    "\n",
    "Display the results in readable form, e.g. show the tagged entities for a reasonably sized part of the data, idealy alongside the original text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bba068a3-4ea1-42bd-a6de-ea16c586bf45",
   "metadata": {
    "id": "bba068a3-4ea1-42bd-a6de-ea16c586bf45",
    "outputId": "9f19d859-c0e7-430e-fb04-5bef44cfafe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.2/12.8 MB 4.6 MB/s eta 0:00:03\n",
      "     - -------------------------------------- 0.5/12.8 MB 6.8 MB/s eta 0:00:02\n",
      "     -- ------------------------------------- 0.9/12.8 MB 6.3 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 1.2/12.8 MB 7.0 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 1.6/12.8 MB 6.8 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 1.9/12.8 MB 7.2 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 2.3/12.8 MB 7.2 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 2.6/12.8 MB 7.2 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 2.9/12.8 MB 7.2 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 3.3/12.8 MB 7.3 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 3.6/12.8 MB 7.2 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 4.0/12.8 MB 7.2 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 4.3/12.8 MB 7.2 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 4.6/12.8 MB 7.2 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 4.9/12.8 MB 7.2 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 5.3/12.8 MB 7.2 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.6/12.8 MB 7.2 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 5.9/12.8 MB 7.1 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 6.2/12.8 MB 7.1 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 6.3/12.8 MB 6.9 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 6.4/12.8 MB 6.6 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 6.9/12.8 MB 6.9 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 6.9 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 7.7/12.8 MB 6.9 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 7.9/12.8 MB 6.8 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 8.2/12.8 MB 6.9 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 8.5/12.8 MB 6.8 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 8.6/12.8 MB 6.6 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.7/12.8 MB 6.5 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.8/12.8 MB 6.4 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.9/12.8 MB 6.2 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.3/12.8 MB 6.2 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.6/12.8 MB 6.3 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.9/12.8 MB 6.3 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.2/12.8 MB 6.2 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.4/12.8 MB 6.2 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.6/12.8 MB 6.2 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 6.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.2/12.8 MB 6.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.5/12.8 MB 6.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.8/12.8 MB 6.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 11.9/12.8 MB 6.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.0/12.8 MB 6.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.8 MB 5.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.2/12.8 MB 5.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 5.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.5/12.8 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 5.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
      "Requirement already satisfied: setuptools in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (58.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.22.3)\n",
      "Requirement already satisfied: language-data>=1.2 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: colorama in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in d:\\studium\\nlp\\nlp_tutorium\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.0)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Tip for Spacy: In order to load a dataset, you might need to download the dataset via command line.\n",
    "#Inside of a notebook, you can run commands with a !-mark\n",
    "\n",
    "#Similar to: !python ...\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f0ffcab-e9c8-4957-9723-14e283a16907",
   "metadata": {
    "id": "5f0ffcab-e9c8-4957-9723-14e283a16907",
    "outputId": "221e080a-a000-418f-a5bf-e5598ac647c8"
   },
   "outputs": [],
   "source": [
    "# read debates\n",
    "import spacy\n",
    "import json\n",
    "\n",
    "with open('data/texts.json', 'r') as infile:\n",
    "    data = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7c112b6-a2ed-4296-b558-9b0cf93f06f8",
   "metadata": {
    "id": "d7c112b6-a2ed-4296-b558-9b0cf93f06f8",
    "outputId": "68bbb3ef-d63c-4d95-ea0d-227f24a0aaba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:  Good evening from Hofstra University in Hempstead, New York.\n",
      "Annotated Entities: [('evening', 'TIME'), ('Hofstra University', 'ORG'), ('Hempstead', 'GPE'), ('New York', 'GPE')]\n",
      "\n",
      "Original Text: I am Lester Holt, anchor of \"NBC Nightly News.”\n",
      "Annotated Entities: [('Lester Holt', 'PERSON'), ('NBC Nightly News', 'ORG')]\n",
      "\n",
      "Original Text: I want to welcome you to the first presidential debate.\n",
      "\n",
      "Annotated Entities: [('first', 'ORDINAL')]\n",
      "\n",
      "Original Text: The participants tonight are Donald Trump and Hillary Clinton.\n",
      "Annotated Entities: [('tonight', 'TIME'), ('Donald Trump', 'PERSON'), ('Hillary Clinton', 'PERSON')]\n",
      "\n",
      "Original Text: This debate is sponsored by the Commission on Presidential Debates, a nonpartisan, nonprofit organization.\n",
      "Annotated Entities: [('the Commission on Presidential Debates', 'ORG')]\n",
      "\n",
      "Original Text: The commission drafted tonight's format, and the rules have been agreed to by the campaigns.\n",
      "\n",
      "Annotated Entities: [('tonight', 'TIME')]\n",
      "\n",
      "Original Text: The 90-minute debate is divided into six segments, each 15 minutes long.\n",
      "Annotated Entities: [('90-minute', 'TIME'), ('six', 'CARDINAL'), ('15 minutes', 'TIME')]\n",
      "\n",
      "Original Text: We'll explore three topic areas tonight:\n",
      "Annotated Entities: [('three', 'CARDINAL'), ('tonight', 'TIME')]\n",
      "\n",
      "Original Text: Achieving prosperity; America's direction; and securing America.\n",
      "Annotated Entities: [('America', 'GPE'), ('America', 'GPE')]\n",
      "\n",
      "Original Text: At the start of each segment, I will ask the same lead-off question to both candidates, and they will each have up to two minutes to respond.\n",
      "Annotated Entities: [('up to two minutes', 'TIME')]\n",
      "\n",
      "Original Text: From that point until the end of the segment, we'll have an open discussion.\n",
      "\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: The questions are mine and have not been shared with the commission or the campaigns.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: The audience here in the room has agreed to remain silent so that we can focus on what the candidates are saying.\n",
      "\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: I will invite you to applaud, however, at this moment, as we welcome the candidates: Democratic nominee for president of the United States, Hillary Clinton, and Republican nominee for president of the United States, Donald J. Trump.\n",
      "\n",
      "Annotated Entities: [('Democratic', 'NORP'), ('the United States', 'GPE'), ('Hillary Clinton', 'PERSON'), ('Republican', 'NORP'), ('the United States', 'GPE'), ('Donald J. Trump', 'PERSON')]\n",
      "\n",
      "Original Text: (APPLAUSE)\n",
      "  \n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: How are you, Donald?\n",
      "(APPLAUSE)\n",
      "  \n",
      "Annotated Entities: [('Donald', 'PERSON')]\n",
      "\n",
      "Original Text: Good luck to you.\n",
      "\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: (APPLAUSE)\n",
      "\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: Well, I do not expect us to cover all the issues of this campaign tonight, but I remind everyone, there are two more presidential debates scheduled.\n",
      "Annotated Entities: [('tonight', 'TIME'), ('two', 'CARDINAL')]\n",
      "\n",
      "Original Text: We are going to focus on many of the issues that voters tell us are most important, and we are going to press for specifics.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: I am honored to have this role, but this evening belongs to the candidates and, just as important, to the American people.\n",
      "\n",
      "Annotated Entities: [('this evening', 'TIME'), ('American', 'NORP')]\n",
      "\n",
      "Original Text: Candidates, we look forward to hearing you articulate your policies and your positions, as well as your visions and your values.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: So, let's begin.\n",
      "\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: we are calling this opening segment \"Achieving Prosperity.”\n",
      "Annotated Entities: [('Achieving Prosperity', 'WORK_OF_ART')]\n",
      "\n",
      "Original Text: And central to that is jobs.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: There are two economic realities in America today.\n",
      "Annotated Entities: [('two', 'CARDINAL'), ('America', 'GPE'), ('today', 'DATE')]\n",
      "\n",
      "Original Text: There's been a record six straight years of job growth, and new census numbers show incomes have increased at a record rate after years of stagnation.\n",
      "Annotated Entities: [('a record six straight years', 'DATE'), ('years', 'DATE')]\n",
      "\n",
      "Original Text: However, income inequality remains significant, and nearly half of Americans are living paycheck to paycheck.\n",
      "\n",
      "Annotated Entities: [('nearly half', 'CARDINAL'), ('Americans', 'NORP')]\n",
      "\n",
      "Original Text: Beginning with you, Secretary Clinton, why are you a better choice than your opponent to create the kinds of jobs that will put more money into the pockets of American works?\n",
      "  \n",
      "Annotated Entities: [('Clinton', 'PERSON'), ('American', 'NORP')]\n",
      "\n",
      "Original Text: Well, thank you, Lester, and thanks to Hofstra for hosting us.\n",
      "\n",
      "Annotated Entities: [('Lester', 'PERSON'), ('Hofstra', 'NORP')]\n",
      "\n",
      "Original Text: The central question in this election is really what kind of country we want to be and what kind of future we'll build together.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: Today is my granddaughter's second birthday, so I think about this a lot.\n",
      "Annotated Entities: [('Today', 'DATE'), ('second', 'ORDINAL')]\n",
      "\n",
      "Original Text: First, we have to build an economy that works for everyone, not just those at the top.\n",
      "Annotated Entities: [('First', 'ORDINAL')]\n",
      "\n",
      "Original Text: That means we need new jobs, good jobs, with rising incomes.\n",
      "\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: I want us to invest in you.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: I want us to invest in your future.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: That means jobs in infrastructure, in advanced manufacturing, innovation and technology, clean, renewable energy, and small business, because most of the new jobs will come from small business.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: We also have to make the economy fairer.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: That starts with raising the national minimum wage and also guarantee, finally, equal pay for women's work.\n",
      "  \n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: I also want to see more companies do profit-sharing.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: If you help create the profits, you should be able to share in them, not just the executives at the top.\n",
      "\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: And I want us to do more to support people who are struggling to balance family and work.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: I've heard from so many of you about the difficult choices you face and the stresses that you're under.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: So let's have paid family leave, earned sick days.\n",
      "Annotated Entities: [('sick days', 'DATE')]\n",
      "\n",
      "Original Text: Let's be sure we have affordable child care and debt-free college.\n",
      "\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: How are we going to do it?\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: we are going to do it by having the wealthy pay their fair share and close the corporate loopholes.\n",
      "\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: Finally, we tonight are on the stage together, Donald Trump and I. Donald, it is good to be with you.\n",
      "Annotated Entities: [('tonight', 'TIME'), ('Donald Trump', 'PERSON'), ('I. Donald', 'PERSON')]\n",
      "\n",
      "Original Text: we are going to have a debate where we are talking about the important issues facing our country.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: You have to judge us, who can shoulder the immense, awesome responsibilities of the presidency, who can put into action the plans that will make your life better.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: I hope that I will be able to earn your vote on November 8th.\n",
      "  \n",
      "Annotated Entities: [('November 8th', 'DATE')]\n",
      "\n",
      "Original Text: Secretary Clinton, thank you.\n",
      "\n",
      "Annotated Entities: [('Clinton', 'PERSON')]\n",
      "\n",
      "Original Text: Mr. Trump, the same question to you.\n",
      "Annotated Entities: [('Trump', 'PERSON')]\n",
      "\n",
      "Original Text: it is about putting money — more money into the pockets of American workers.\n",
      "Annotated Entities: [('American', 'NORP')]\n",
      "\n",
      "Original Text: You have up to two minutes.\n",
      "  \n",
      "Annotated Entities: [('up to two minutes', 'TIME')]\n",
      "\n",
      "Original Text: Thank you, Lester.\n",
      "Annotated Entities: [('Lester', 'PERSON')]\n",
      "\n",
      "Original Text: Our jobs are fleeing the country.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: they are going to Mexico.\n",
      "Annotated Entities: [('Mexico', 'GPE')]\n",
      "\n",
      "Original Text: they are going to many other countries.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: You look at what China is doing to our country in terms of making our product.\n",
      "Annotated Entities: [('China', 'GPE')]\n",
      "\n",
      "Original Text: they are devaluing their currency, and there's nobody in our government to fight them.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: And we have a very good fight.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: And we have a winning fight.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: Because they are using our country as a piggy bank to rebuild China, and many other countries are doing the same thing.\n",
      "\n",
      "Annotated Entities: [('China', 'GPE')]\n",
      "\n",
      "Original Text: So we are losing our good jobs, so many of them.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: When you look at what's happening in Mexico, a friend of mine who builds plants said it is the eighth wonder of the world.\n",
      "Annotated Entities: [('Mexico', 'GPE'), ('eighth', 'ORDINAL')]\n",
      "\n",
      "Original Text: they are building some of the biggest plants anywhere in the world, some of the most sophisticated, some of the best plants.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: With the United States, as he said, not so much.\n",
      "\n",
      "Annotated Entities: [('the United States', 'GPE')]\n",
      "\n",
      "Original Text: So Ford is leaving.\n",
      "Annotated Entities: [('Ford', 'ORG')]\n",
      "\n",
      "Original Text: You see that, their small car division leaving.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: Thousands of jobs leaving Michigan, leaving Ohio.\n",
      "Annotated Entities: [('Thousands', 'CARDINAL'), ('Michigan', 'GPE'), ('Ohio', 'GPE')]\n",
      "\n",
      "Original Text: they are all leaving.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: And we can not allow it to happen anymore.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: As far as child care is concerned and so many other things, I think Hillary and I agree on that.\n",
      "Annotated Entities: [('Hillary', 'PERSON')]\n",
      "\n",
      "Original Text: We probably disagree a little bit as to numbers and amounts and what we are going to do, but perhaps we'll be talking about that later.\n",
      "\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: But we have to stop our jobs from being stolen from us.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: We have to stop our companies from leaving the United States and, with it, firing all of their people.\n",
      "Annotated Entities: [('the United States', 'GPE')]\n",
      "\n",
      "Original Text: All you have to do is take a look at Carrier air conditioning in Indianapolis.\n",
      "Annotated Entities: [('Carrier air', 'LOC'), ('Indianapolis', 'GPE')]\n",
      "\n",
      "Original Text: They left — fired 1,400 people.\n",
      "Annotated Entities: [('1,400', 'CARDINAL')]\n",
      "\n",
      "Original Text: they are going to Mexico.\n",
      "Annotated Entities: [('Mexico', 'GPE')]\n",
      "\n",
      "Original Text: So many hundreds and hundreds of companies are doing this.\n",
      "  \n",
      "Annotated Entities: [('So many hundreds and hundreds', 'CARDINAL')]\n",
      "\n",
      "Original Text: We cannot let it happen.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: Under my plan, I'll be reducing taxes tremendously, from 35 percent to 15 percent for companies, small and big businesses.\n",
      "Annotated Entities: [('35 percent', 'PERCENT'), ('15 percent', 'PERCENT')]\n",
      "\n",
      "Original Text: That's going to be a job creator like we haven't seen since Ronald Reagan.\n",
      "Annotated Entities: [('Ronald Reagan', 'PERSON')]\n",
      "\n",
      "Original Text: it is going to be a beautiful thing to watch.\n",
      "\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: Companies will come.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: They will build.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: They will expand.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: New companies will start.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: And I look very, very much forward to doing it.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: We have to renegotiate our trade deals, and we have to stop these countries from stealing our companies and our jobs.\n",
      "  \n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: Secretary Clinton, would you like to respond?\n",
      "  \n",
      "Annotated Entities: [('Clinton', 'PERSON')]\n",
      "\n",
      "Original Text: Well, I think that trade is an important issue.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: Of course, we are 5 percent of the world's population; we have to trade with the other 95 percent.\n",
      "Annotated Entities: [('5 percent', 'PERCENT'), ('the other 95 percent', 'PERCENT')]\n",
      "\n",
      "Original Text: And we need to have smart, fair trade deals.\n",
      "\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: We also, though, need to have a tax system that rewards work and not just financial transactions.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: And the kind of plan that Donald has put forth would be trickle-down economics all over again.\n",
      "Annotated Entities: [('Donald', 'PERSON')]\n",
      "\n",
      "Original Text: In fact, it would be the most extreme version, the biggest tax cuts for the top percent of the people in this country than we've ever had.\n",
      "\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: I call it trumped-up trickle-down, because that's exactly what it would be.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: That is not how we grow the economy.\n",
      "\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: We just have a different view about what's best for growing the economy, how we make investments that will actually produce jobs and rising incomes.\n",
      "\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: I think we come at it from somewhat different perspectives.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: I understand that.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: You know, Donald was very fortunate in his life, and that's all to his benefit.\n",
      "Annotated Entities: [('Donald', 'PERSON')]\n",
      "\n",
      "Original Text: He started his business with $14 million, borrowed from his father, and he really believes that the more you help wealthy people, the better off we'll be and that everything will work out from there.\n",
      "\n",
      "Annotated Entities: [('$14 million', 'MONEY')]\n",
      "\n",
      "Original Text: I do not buy that.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: I have a different experience.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: My father was a small-businessman.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: He worked really hard.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: He printed drapery fabrics on long tables, where he pulled out those fabrics and he went down with a silkscreen and dumped the paint in and took the squeegee and kept going.\n",
      "\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: And so what I believe is the more we can do for the middle class, the more we can invest in you, your education, your skills, your future, the better we will be off and the better we'll grow.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: That's the kind of economy I want us to see again.\n",
      "  \n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: Let me follow up with Mr. Trump, if you can.\n",
      "Annotated Entities: [('Trump', 'PERSON')]\n",
      "\n",
      "Original Text: You've talked about creating 25 million jobs, and you've promised to bring back millions of jobs for Americans.\n",
      "Annotated Entities: [('25 million', 'CARDINAL'), ('millions', 'CARDINAL'), ('Americans', 'NORP')]\n",
      "\n",
      "Original Text: How are you going to bring back the industries that have left this country for cheaper labor overseas?\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: How, specifically, are you going to tell American manufacturers that you have to come back?\n",
      "  \n",
      "Annotated Entities: [('American', 'NORP')]\n",
      "\n",
      "Original Text: Well, for one thing — and before we start on that — my father gave me a very small loan in 1975, and I built it into a company that's worth many, many billions of dollars, with some of the greatest assets in the world, and I say that only because that's the kind of thinking that our country needs.\n",
      "\n",
      "Annotated Entities: [('one', 'CARDINAL'), ('1975', 'DATE'), ('many billions of dollars', 'MONEY')]\n",
      "\n",
      "Original Text: Our country's in deep trouble.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: We do not know what we are doing when it comes to devaluations and all of these countries all over the world, especially China.\n",
      "Annotated Entities: [('China', 'GPE')]\n",
      "\n",
      "Original Text: they are the best, the best ever at it.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: What they are doing to us is a very, very sad thing.\n",
      "\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: So we have to do that.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: We have to renegotiate our trade deals.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: And, Lester, they are taking our jobs, they are giving incentives, they are doing things that, frankly, we do not do.\n",
      "\n",
      "Annotated Entities: [('Lester', 'PERSON')]\n",
      "\n",
      "Original Text: Let me give you the example of Mexico.\n",
      "Annotated Entities: [('Mexico', 'GPE')]\n",
      "\n",
      "Original Text: They have a VAT tax.\n",
      "Annotated Entities: [('VAT', 'ORG')]\n",
      "\n",
      "Original Text: we are on a different system.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: When we sell into Mexico, there's a tax.\n",
      "Annotated Entities: [('Mexico', 'GPE')]\n",
      "\n",
      "Original Text: When they sell in — automatic, 16 percent, approximately.\n",
      "Annotated Entities: [('16 percent', 'PERCENT')]\n",
      "\n",
      "Original Text: When they sell into us, there's no tax.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: it is a defective agreement.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: it is been defective for a long time, many years, but the politicians haven't done anything about it.\n",
      "\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: Now, in all fairness to Secretary Clinton — yes, is that OK?\n",
      "Annotated Entities: [('Clinton', 'PERSON')]\n",
      "\n",
      "Original Text: Good.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: I want you to be very happy.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: it is very important to me.\n",
      "\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: But in all fairness to Secretary Clinton, when she started talking about this, it was really very recently.\n",
      "Annotated Entities: [('Clinton', 'PERSON')]\n",
      "\n",
      "Original Text: she is been doing this for 30 years.\n",
      "Annotated Entities: [('30 years', 'DATE')]\n",
      "\n",
      "Original Text: And why hasn't she made the agreements better?\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: The NAFTA agreement is defective.\n",
      "Annotated Entities: [('NAFTA', 'ORG')]\n",
      "\n",
      "Original Text: Just because of the tax and many other reasons, but just because of the fact…\n",
      "  Let me interrupt just a moment, but…\n",
      "  Secretary Clinton and others, politicians, should have been doing this for years, not right now, because of the fact that we've created a movement.\n",
      "Annotated Entities: [('Clinton', 'PERSON'), ('years', 'DATE')]\n",
      "\n",
      "Original Text: They should have been doing this for years.\n",
      "Annotated Entities: [('years', 'DATE')]\n",
      "\n",
      "Original Text: What's happened to our jobs and our country and our economy generally is — look, we owe $20 trillion.\n",
      "Annotated Entities: [('$20 trillion', 'MONEY')]\n",
      "\n",
      "Original Text: We cannot do it any longer, Lester.   \n",
      "Annotated Entities: [('Lester', 'PERSON')]\n",
      "\n",
      "Original Text: Back to the question, though.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: How do you bring back — specifically bring back jobs, American manufacturers?\n",
      "Annotated Entities: [('American', 'NORP')]\n",
      "\n",
      "Original Text: How do you make them bring the jobs back?\n",
      "  \n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: Well, the first thing you do is do not let the jobs leave.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: The companies are leaving.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: I could name, I mean, there are thousands of them.\n",
      "Annotated Entities: [('thousands', 'CARDINAL')]\n",
      "\n",
      "Original Text: they are leaving, and they are leaving in bigger numbers than ever.\n",
      "\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: And what you do is you say, fine, you want to go to Mexico or some other country, good luck.\n",
      "Annotated Entities: [('Mexico', 'GPE')]\n",
      "\n",
      "Original Text: We wish you a lot of luck.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: But if you think you're going to make your air conditioners or your cars or your cookies or whatever you make and bring them into our country without a tax, you're wrong.\n",
      "\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: And once you say you're going to have to tax them coming in, and our politicians never do this, because they have special interests and the special interests want those companies to leave, because in many cases, they own the companies.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: So what I am saying is, we can stop them from leaving.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: We have to stop them from leaving.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: And that's a big, big factor.\n",
      "  \n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: Let me let Secretary Clinton get in here.\n",
      "  \n",
      "Annotated Entities: [('Clinton', 'PERSON')]\n",
      "\n",
      "Original Text: Well, let's stop for a second and remember where we were eight years ago.\n",
      "Annotated Entities: [('second', 'ORDINAL'), ('eight years ago', 'DATE')]\n",
      "\n",
      "Original Text: We had the worst financial crisis, the Great Recession, the worst since the 1930s.\n",
      "Annotated Entities: [('the Great Recession', 'EVENT'), ('the 1930s', 'DATE')]\n",
      "\n",
      "Original Text: That was in large part because of tax policies that slashed taxes on the wealthy, failed to invest in the middle class, took their eyes off of Wall Street, and created a perfect storm.\n",
      "\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: In fact, Donald was one of the people who rooted for the housing crisis.\n",
      "Annotated Entities: [('Donald', 'PERSON')]\n",
      "\n",
      "Original Text: He said, back in 2006, \"Gee, I hope it does collapse, because then I can go in and buy some and make some money.”\n",
      "Annotated Entities: [('2006', 'DATE')]\n",
      "\n",
      "Original Text: Well, it did collapse.\n",
      "  \n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: That's called business, by the way.\n",
      "  \n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: Nine million people — nine million people lost their jobs.\n",
      "Annotated Entities: [('Nine million', 'CARDINAL'), ('nine million', 'CARDINAL')]\n",
      "\n",
      "Original Text: Five million people lost their homes.\n",
      "Annotated Entities: [('Five million', 'CARDINAL')]\n",
      "\n",
      "Original Text: And $13 trillion in family wealth was wiped out.\n",
      "\n",
      "Annotated Entities: [('$13 trillion', 'MONEY')]\n",
      "\n",
      "Original Text: Now, we have come back from that abyss.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: And it has not been easy.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: So we are now on the precipice of having a potentially much better economy, but the last thing we need to do is to go back to the policies that failed us in the first place.\n",
      "\n",
      "Annotated Entities: [('first', 'ORDINAL')]\n",
      "\n",
      "Original Text: Independent experts have looked at what I've proposed and looked at what Donald's proposed, and basically they've said this, that if his tax plan, which would blow up the debt by over $5 trillion and would in some instances disadvantage middle-class families compared to the wealthy, were to go into effect, we would lose 3.5 million jobs and maybe have another recession.\n",
      "\n",
      "Annotated Entities: [('Donald', 'PERSON'), ('over $5 trillion', 'MONEY'), ('3.5 million', 'CARDINAL')]\n",
      "\n",
      "Original Text: They've looked at my plans and they've said, OK, if we can do this, and I intend to get it done, we will have 10 million more new jobs, because we will be making investments where we can grow the economy.\n",
      "Annotated Entities: [('10 million', 'CARDINAL')]\n",
      "\n",
      "Original Text: Take clean energy.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: Some country is going to be the clean- energy superpower of the 21st century.\n",
      "Annotated Entities: [('clean-', 'CARDINAL'), ('the 21st century', 'DATE')]\n",
      "\n",
      "Original Text: Donald thinks that climate change is a hoax perpetrated by the Chinese.\n",
      "Annotated Entities: [('Donald', 'PERSON'), ('Chinese', 'NORP')]\n",
      "\n",
      "Original Text: I think it is real.\n",
      "  \n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: I did not.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: I did not.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: I do not say that.\n",
      "  \n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: I think science is real.\n",
      "  \n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: I do not say that.\n",
      "  \n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: And I think it is important that we grip this and deal with it, both at home and abroad.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: And here's what we can do.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: We can deploy a half a billion more solar panels.\n",
      "Annotated Entities: [('a half a billion', 'QUANTITY')]\n",
      "\n",
      "Original Text: We can have enough clean energy to power every home.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: We can build a new modern electric grid.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: That's a lot of jobs; that's a lot of new economic activity.\n",
      "\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: So I've tried to be very specific about what we can and should do, and I am determined that we are going to get the economy really moving again, building on the progress we've made over the last eight years, but never going back to what got us in trouble in the first place.\n",
      "  \n",
      "Annotated Entities: [('the last eight years', 'DATE'), ('first', 'ORDINAL')]\n",
      "\n",
      "Original Text: Mr. Trump?\n",
      "  She talks about solar panels.\n",
      "Annotated Entities: [('Trump', 'PERSON')]\n",
      "\n",
      "Original Text: We invested in a solar company, our country.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: That was a disaster.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: They lost plenty of money on that one.\n",
      "\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: Now, look, I am a great believer in all forms of energy, but we are putting a lot of people out of work.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: Our energy policies are a disaster.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: Our country is losing so much in terms of energy, in terms of paying off our debt.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: You can not do what you're looking to do with $20 trillion in debt.\n",
      "\n",
      "Annotated Entities: [('$20 trillion', 'MONEY')]\n",
      "\n",
      "Original Text: The Obama administration, from the time they've come in, is over 230 years' worth of debt, and he is topped it.\n",
      "Annotated Entities: [('Obama', 'PERSON'), (\"230 years'\", 'DATE')]\n",
      "\n",
      "Original Text: he is doubled it in a course of almost eight years, seven-and-a-half years, to be semi- exact.\n",
      "\n",
      "Annotated Entities: [('almost eight years', 'DATE'), ('seven', 'CARDINAL')]\n",
      "\n",
      "Original Text: So I will tell you this.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: We have to do a much better job at keeping our jobs.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: And we have to do a much better job at giving companies incentives to build new companies or to expand, because they are not doing it.\n",
      "\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: And all you have to do is look at Michigan and look at Ohio and look at all of these places where so many of their jobs and their companies are just leaving, they are gone.\n",
      "\n",
      "Annotated Entities: [('Michigan', 'GPE'), ('Ohio', 'GPE')]\n",
      "\n",
      "Original Text: And, Hillary, I'd just ask you this.\n",
      "Annotated Entities: [('Hillary', 'PERSON')]\n",
      "\n",
      "Original Text: You've been doing this for 30 years.\n",
      "Annotated Entities: [('30 years', 'DATE')]\n",
      "\n",
      "Original Text: Why are you just thinking about these solutions right now?\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: For 30 years, you've been doing it, and now you're just starting to think of solutions.\n",
      "  \n",
      "Annotated Entities: [('30 years', 'DATE')]\n",
      "\n",
      "Original Text: Well, actually…\n",
      "  I will bring — excuse me.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: I will bring back jobs.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: You can not bring back jobs.\n",
      "  \n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: Well, actually, I have thought about this quite a bit.\n",
      "  \n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: Yeah, for 30 years.\n",
      "  \n",
      "Annotated Entities: [('30 years', 'DATE')]\n",
      "\n",
      "Original Text: And I have — well, not quite that long.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: I think my husband did a pretty good job in the 1990s.\n",
      "Annotated Entities: [('the 1990s', 'DATE')]\n",
      "\n",
      "Original Text: I think a lot about what worked and how we can make it work again…\n",
      "  Well, he approved NAFTA…\n",
      "(CROSSTALK)\n",
      "  … million new jobs, a balanced budget…\n",
      "  He approved NAFTA, which is the single worst trade deal ever approved in this country.\n",
      "  \n",
      "Annotated Entities: [('NAFTA', 'ORG'), ('CROSSTALK', 'ORG'), ('million', 'CARDINAL'), ('NAFTA', 'ORG')]\n",
      "\n",
      "Original Text: Incomes went up for everybody.\n",
      "Annotated Entities: [('Incomes', 'PERSON')]\n",
      "\n",
      "Original Text: Manufacturing jobs went up also in the 1990s, if we are actually going to look at the facts.\n",
      "\n",
      "Annotated Entities: [('the 1990s', 'DATE')]\n",
      "\n",
      "Original Text: When I was in the Senate, I had a number of trade deals that came before me, and I held them all to the same test.\n",
      "Annotated Entities: [('Senate', 'ORG')]\n",
      "\n",
      "Original Text: Will they create jobs in America?\n",
      "Annotated Entities: [('America', 'GPE')]\n",
      "\n",
      "Original Text: Will they raise incomes in America?\n",
      "Annotated Entities: [('America', 'GPE')]\n",
      "\n",
      "Original Text: And are they good for our national security?\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: Some of them I voted for.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: The biggest one, a multinational one known as CAFTA, I voted against.\n",
      "Annotated Entities: [('CAFTA', 'ORG')]\n",
      "\n",
      "Original Text: And because I hold the same standards as I look at all of these trade deals.\n",
      "\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: But let's not assume that trade is the only challenge we have in the economy.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: I think it is a part of it, and I've said what I am going to do.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: I am going to have a special prosecutor.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: we are going to enforce the trade deals we have, and we are going to hold people accountable.\n",
      "\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: When I was secretary of state, we actually increased American exports globally 30 percent.\n",
      "Annotated Entities: [('American', 'NORP'), ('30 percent', 'PERCENT')]\n",
      "\n",
      "Original Text: We increased them to China 50 percent.\n",
      "Annotated Entities: [('China', 'GPE'), ('50 percent', 'PERCENT')]\n",
      "\n",
      "Original Text: So I know how to really work to get new jobs and to get exports that helped to create more new jobs.\n",
      "  \n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: Very quickly…\n",
      "  \n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: But you haven't done it in 30 years or 26 years or any number you want to…\n",
      "  \n",
      "Annotated Entities: [('30 years', 'DATE'), ('26 years', 'DATE')]\n",
      "\n",
      "Original Text: Well, I've been a senator, Donald…\n",
      "  You haven't done it.\n",
      "Annotated Entities: [('Donald', 'PERSON')]\n",
      "\n",
      "Original Text: You haven't done it.\n",
      "  \n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: And I have been a secretary of state…\n",
      "  Excuse me.\n",
      "  \n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: And I have done a lot…\n",
      "  Your husband signed NAFTA, which was one of the worst things that ever happened to the manufacturing industry.\n",
      "  \n",
      "Annotated Entities: [('NAFTA', 'ORG')]\n",
      "\n",
      "Original Text: Well, that's your opinion.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: That is your opinion.\n",
      "  \n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: You go to New England, you go to Ohio, Pennsylvania, you go anywhere you want, Secretary Clinton, and you will see devastation where manufacture is down 30, 40, sometimes 50 percent.\n",
      "Annotated Entities: [('New England', 'LOC'), ('Ohio', 'GPE'), ('Pennsylvania', 'GPE'), ('Clinton', 'PERSON'), ('30', 'CARDINAL'), ('40', 'DATE'), ('50 percent', 'PERCENT')]\n",
      "\n",
      "Original Text: NAFTA is the worst trade deal maybe ever signed anywhere, but certainly ever signed in this country.\n",
      "\n",
      "Annotated Entities: [('NAFTA', 'ORG')]\n",
      "\n",
      "Original Text: And now you want to approve Trans-Pacific Partnership.\n",
      "Annotated Entities: [('Trans-Pacific Partnership', 'ORG')]\n",
      "\n",
      "Original Text: You were totally in favor of it.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: Then you heard what I was saying, how bad it is, and you said, I can not win that debate.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: But you know that if you did win, you would approve that, and that will be almost as bad as NAFTA.\n",
      "Annotated Entities: [('NAFTA', 'ORG')]\n",
      "\n",
      "Original Text: Nothing will ever top NAFTA.\n",
      "  \n",
      "Annotated Entities: [('NAFTA', 'ORG')]\n",
      "\n",
      "Original Text: Well, that is just not accurate.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: I was against it once it was finally negotiated and the terms were laid out.\n",
      "Annotated Entities: []\n",
      "\n",
      "Original Text: I wrote about that in…\n",
      "  You called it the gold standard.\n",
      "\n",
      "Annotated Entities: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your Code Submission goes here\n",
    "\n",
    "content_debates = data['debates']\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(content_debates)\n",
    "first_250_sentences = list(doc.sents)[:250]\n",
    "\n",
    "annotated_sentences = [{'text': sentence.text, 'entities': [(ent.text, ent.label_) for ent in sentence.ents]} for sentence in first_250_sentences]\n",
    "\n",
    "for annotated_sentence in annotated_sentences:\n",
    "    print(\"Original Text:\", annotated_sentence['text'])\n",
    "    print(\"Annotated Entities:\", annotated_sentence['entities'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f422a995-6384-4ae3-aa68-42d1926fac49",
   "metadata": {
    "id": "f422a995-6384-4ae3-aa68-42d1926fac49"
   },
   "source": [
    "### Part 2: Analysis\n",
    "\n",
    "In real-word use cases, NER can be difficult. Analyze the following challenging examples and identify all cases in which the automated NER failed. For the tagging, you can use the method from part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a8b065a-bf5a-42bb-934b-769fe4f3f477",
   "metadata": {
    "id": "0a8b065a-bf5a-42bb-934b-769fe4f3f477"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data/hard_data.json', 'r', encoding='utf-8') as infile:\n",
    "    data = json.load(infile)\n",
    "\n",
    "test_sentences = [s[\"sentence\"] for s in data['test_sentences']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a9ff0a-6a7b-44e8-a52d-ea3d060369dc",
   "metadata": {
    "id": "a2a9ff0a-6a7b-44e8-a52d-ea3d060369dc"
   },
   "source": [
    "Write the failure cases down here, then try to classify them into types of errors that the model makes. Discuss the results.\n",
    "You can use a mixture of markdown and code if it suits your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a774e516-db3a-42c0-9af3-94cfc112e8ca",
   "metadata": {
    "id": "a774e516-db3a-42c0-9af3-94cfc112e8ca",
    "outputId": "3698c009-853e-4f37-869b-8b870ed0e69c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: Flight booking 1: “So, I would like to fly out sometime tonight and fly back in the evening in 4 days. From I’m looking to go to Denver. I’m flying out of San Francisco.”\n",
      "Annotated Entities: [('1', 'CARDINAL'), ('tonight', 'TIME'), ('4 days', 'DATE'), ('Denver', 'GPE'), ('San Francisco', 'GPE')]\n",
      "\n",
      "Original Text: Flight booking 2: “Okay, you got it so it looks like United Airlines leaves at 9:20 p.m. that is nonstop the flight duration is 2 hours and 28 minutes and is priced at $337.”\n",
      "Annotated Entities: [('2', 'CARDINAL'), ('United Airlines', 'ORG'), ('9:20 p.m.', 'TIME'), ('2 hours and 28 minutes', 'TIME'), ('337', 'MONEY')]\n",
      "\n",
      "Original Text: Flight booking 3: “I found a flight that leaves Seattle coming Monday at 7:35 a.m and arrives in Tampa at 4:10 p.m.”\n",
      "Annotated Entities: [('3', 'CARDINAL'), ('Seattle', 'GPE'), ('coming Monday', 'DATE'), ('Tampa', 'GPE'), ('4:10 p.m.', 'TIME')]\n",
      "\n",
      "Original Text: Hotel booking 1: “Park Hyatt Aviara resort Golf Club and Spa, it’s $279 per night. It‘s rated 4.8 stars. Resort offering an 18-hole golf course, an outdoor pool & tennis courts plus a spa & fine dining.”\n",
      "Annotated Entities: [('1', 'CARDINAL'), ('Golf Club', 'ORG'), ('279', 'MONEY'), ('4.8', 'CARDINAL'), ('18', 'CARDINAL')]\n",
      "\n",
      "Original Text: Hotel booking 2: “Staybridge Suites Carlsbad, it’s $145 per night. It’s rated 4.5 stars. Warm suites with kitchens in a relaxed property featuring an outdoor pool, a gym & a BBQ area.”\n",
      "Annotated Entities: [('2', 'CARDINAL'), ('Staybridge Suites Carlsbad', 'WORK_OF_ART'), ('145', 'MONEY'), ('4.5', 'CARDINAL')]\n",
      "\n",
      "Original Text: Cinema 1: “The Mummy is playing at 4:30 pm this afternoon at Regal Davis Stadium 5.”\n",
      "Annotated Entities: [('Mummy', 'PERSON'), ('4:30 pm this afternoon', 'TIME'), ('Regal Davis Stadium', 'FAC')]\n",
      "\n",
      "Original Text: Cinema 2: “I have Chips playing at 9:50 PM. I have Get Out playing at 10:15 PM. and Snaps playing at 10:25 PM.”\n",
      "Annotated Entities: [('2', 'CARDINAL'), ('9:50 PM', 'TIME'), ('Get Out', 'EVENT'), ('10:15 PM', 'TIME'), ('Snaps', 'GPE'), ('10:25 PM', 'TIME')]\n",
      "\n",
      "Original Text: Music 1: “Here’s a song diamonds originally by Rihanna Cover by One Voice Children’s Choir.”\n",
      "Annotated Entities: [('Rihanna Cover', 'PERSON'), ('One Voice Children’s Choir', 'ORG')]\n",
      "\n",
      "Original Text: Restaurant 1: “Hi, currently I’m in IKEA, California. I’m looking for restaurant to eat dinner.”\n",
      "Annotated Entities: [('California', 'GPE')]\n",
      "\n",
      "Original Text: Restaurant 2: “I found a highly rated restaurant called Second Floor in Kitchen, it is 4.3 stars out of 5 and it’s described is New American tasting menus in a sophisticated setting. How does it sound?”\n",
      "Annotated Entities: [('Second Floor', 'ORG'), ('Kitchen', 'GPE'), ('4.3', 'CARDINAL'), ('5', 'CARDINAL'), ('New American', 'NORP')]\n",
      "\n",
      "Original Text: Sports 1: “On last Saturday, September 9th, LA Dodgers played against New York Red Bulls and it was a draw with the score 1–1.”\n",
      "Annotated Entities: [('1', 'CARDINAL'), ('last Saturday, September 9th', 'DATE'), ('LA Dodgers', 'ORG'), ('New York Red Bulls', 'ORG')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('data/hard_data.json', 'r', encoding='utf-8') as infile:\n",
    "    data = json.load(infile)\n",
    "\n",
    "test_sentences = [s[\"sentence\"] for s in data['test_sentences']]\n",
    "\n",
    "annotated_sentences = []\n",
    "for sentence in test_sentences:\n",
    "    doc = nlp(sentence)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    annotated_sentences.append({'text': sentence, 'entities': entities})\n",
    "\n",
    "for annotated_sentence in annotated_sentences:\n",
    "    print(\"Original Text:\", annotated_sentence['text'])\n",
    "    print(\"Annotated Entities:\", annotated_sentence['entities'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548b6e5e-cad5-4c2b-a9c1-5846867acf86",
   "metadata": {
    "id": "548b6e5e-cad5-4c2b-a9c1-5846867acf86"
   },
   "source": [
    "# Entity Annotations Categories\n",
    "(source: https://dataknowsall.com/blog/ner.html)\n",
    "\n",
    "- PERSON:      People, including fictional.\n",
    "- NORP:        Nationalities or religious or political groups.\n",
    "- FAC:         Buildings, airports, highways, bridges, etc.\n",
    "- ORG:         Companies, agencies, institutions, etc.\n",
    "- GPE:         Countries, cities, states.\n",
    "- LOC:         Non-GPE locations, mountain ranges, bodies of water.\n",
    "- PRODUCT:     Objects, vehicles, foods, etc. (Not services.)\n",
    "- EVENT:       Named hurricanes, battles, wars, sports events, etc.\n",
    "- WORK_OF_ART: Titles of books, songs, etc.\n",
    "- LAW:         Named documents made into laws.\n",
    "- LANGUAGE:    Any named language.\n",
    "- DATE:        Absolute or relative dates or periods.\n",
    "- TIME:        Times smaller than a day.\n",
    "- PERCENT:     Percentage, including ”%“.\n",
    "- MONEY:       Monetary values, including unit.\n",
    "- QUANTITY:    Measurements, as of weight or distance.\n",
    "- ORDINAL:     “first”, “second”, etc.\n",
    "- CARDINAL:    Numerals that do not fall under another type.\n",
    "\n",
    "# Possible NER-Failure Classifications\n",
    "- Incomplete Entity: When the recognized entity is not fully captured or is only partially identified\n",
    "- Missing Entity: When an entity is present in the text but not detected by the NER system\n",
    "- Misclassification of an Entity: When an entity is assigned to the wrong category\n",
    "- Ambigious Entity: When the context of the entity is unclear, making it difficult to accurately classify\n",
    "- False positive: When an entity is not present in the text, but is recognized and returned by the system\n",
    "\n",
    "## Flight Booking 1:\n",
    "    -\n",
    "## Flight Booking 2:\n",
    "    - Incomplete Entity: '337' as MONEY ==> should be: '$337'\n",
    "    \n",
    "## Flight Booking 3:\n",
    "    - Missing Entity: '7:35 a.m' as TIME\n",
    "    \n",
    "## Hotel booking 1:\n",
    "    - Incomplete Entity: 'Golf Club' is annotated as 'ORG' ==> should be: 'Park Hyatt Aviara resort Golf Club and Spa' as 'ORG'\n",
    "    - Incomplete Entity: '279' as MONEY should be: '$279'\n",
    "    \n",
    "## Hotel booking 2:\n",
    "    - Misclassification: 'Staybridge Suites Carlsbad' is annotated as 'WORK_OF_ART' ==> should be 'ORG'\n",
    "    - Incomplete Entity: '145' as MONEY ==> should be '$145'\n",
    "## Cinema 1:\n",
    "    - Missing Entity: '1' as CARDINAL\n",
    "    - Misclassification: 'The Mummy' is annotated as 'PERSON' ==> should be 'WORK_OF_ART'\n",
    "    - Misclassification: 'Regal Davis Stadium 5' is annotated as 'FAC' ==> should be 'ORG'\n",
    "## Cinema 2:\n",
    "    - Missing Entity: 'Chips' as 'WORK_OF_ART'\n",
    "    - Misclassification: 'Get Out' is annotated as 'EVENT' ==> should be 'WORK_OF_ART'\n",
    "    - Misclassification: 'Snaps' is annotated as 'GPE' ==> should be 'WORK_OF_ART'\n",
    "## Music 1:\n",
    "    - Missing Entity: '1' as CARDINAL\n",
    "    - Missing Entity: 'diamonds' as 'WORK_OF_ART'\n",
    "    - Ambigous Entity Error: 'Rihanna Cover' is annotated as 'PERSON' ==> should be Cover by Rihanna (WORK_OF_ART) but could also be Rihanna (PERSON)\n",
    "## Restaurant 1:\n",
    "    - Missing Entity: '1' as CARDINAL\n",
    "    - Missing Entity: 'IKEA' as 'ORG'\n",
    "## Restaurant 2:\n",
    "    - Missing Entity: '1' as CARDINAL\n",
    "    - Incomplete Entity: 'Second Floor' is annotated as 'ORG' ==> should be 'Second Floor in Kitchen' as 'ORG'\n",
    "    - Ambigous Entity Error: 'Second Floor in Kitchen' could be 'ORG' but could also be 'ORDINAL' (Second)\n",
    "    - False-Positive Error: 'Kitchen' as 'GPE'\n",
    "    - Ambigous Entity Error: 'New American' as 'NORP'\n",
    "## Sports 1:\n",
    "    - Missing Entity: '1–1' as CARDINAL\n",
    "\n",
    "\n",
    "# Leads to 22 NER-Failures:\n",
    "## 5x Incomplete Entity\n",
    "## 8x Missing Entity\n",
    "## 5x Misclassification\n",
    "## 3x Ambigous Entity Error\n",
    "## 1x False Positive Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ff1cc-67ab-468d-a1db-b5b4cb806db0",
   "metadata": {
    "id": "fb4ff1cc-67ab-468d-a1db-b5b4cb806db0"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9653c77e-ca28-4ee5-8c5f-cca95cbc5ae0",
   "metadata": {
    "id": "9653c77e-ca28-4ee5-8c5f-cca95cbc5ae0"
   },
   "source": [
    "#### Submitting your results:\n",
    "\n",
    "To submit your results, please:\n",
    "\n",
    "- save this file, i.e., `ex??_assignment.ipynb`.\n",
    "- if you reference any external files (e.g., images), please create a zip or rar archieve and put the notebook files and all referenced files in there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd431e5-dc4b-4a35-8173-bb11b9cfccdc",
   "metadata": {
    "id": "1fd431e5-dc4b-4a35-8173-bb11b9cfccdc"
   },
   "source": [
    "**Remarks:**\n",
    "    \n",
    "- Do not copy any code from the Internet. In case you want to use publicly available code, please, add the reference to the respective code snippet.\n",
    "- Check your code compiles and executes, even after you have restarted the Kernel.\n",
    "- Submit your written solutions and the coding exercises within the provided spaces and not otherwise.\n",
    "- Write the names of your partner and your name in the top section."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
