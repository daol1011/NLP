{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b83cf750-33a5-4457-9a8c-4b13b4c44cd4",
   "metadata": {},
   "source": [
    "## Natural Language Processing - Summer Term 2024\n",
    "### Hochschule Karlsruhe\n",
    "### Lecturer: Prof. Dr. Jannik Strötgen\n",
    "### Tutor: Paul Löhr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8112aade9870a28",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Gruppe:\n",
    "- Daniel Schneider\n",
    "- Leonie Bäder\n",
    "- Maximilian Hoffmann"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f675e5c2-c60f-43e9-9076-a3bf7a36ffa1",
   "metadata": {},
   "source": [
    "# Exercise 03\n",
    "\n",
    "You will learn about:\n",
    "    \n",
    "- The Brown Corpus\n",
    "- Part of Speech (POS) tagging\n",
    "- Unigram and Bigram tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd621e3-4f8e-4fbb-88e2-8910fca352ee",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67b77e4-4f2e-4441-85e3-5a007faa73c7",
   "metadata": {},
   "source": [
    "## Task 1 - The Brown Corpus (8 P):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fbabdb-28ad-414c-b4fd-5d8e244e793a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42de428-53b6-4a0e-8311-3ecd0dafa6d7",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "\n",
    "In the following, we will use the _Brown Corpus_. In one or two sentences, describe what the _Brown Corpus_ is and how it can be used for POS tagging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8371ef-3de2-43fa-87f7-081800a53e65",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "The Brown Corpus is a large collection of English texts/ tagset, totaling over one million words and sampled from a wide range of sources and genres. It serves as a valuable resource for training and evaluating POS tagging algorithms in NLP. It provides labeled examples of word sequences with their corresponding POS tags, which can be used to develop and improve automatic tagging systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09200db1-e168-4173-a85e-92c5630ddabc",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "We start by analyzing which tags occur in the brown corpus. For this, you should extract the `tagged_words` first. Then\n",
    "\n",
    "1. List the first 20 entries and\n",
    "2. then list the ten most common tags in the category `news`.\n",
    "\n",
    "In the lecture, we use the Brown Corpus POS tags (default, i.e., `tagset=None`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d48b5e71-e2ed-4b57-af65-f352d0873632",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T16:36:45.259424Z",
     "start_time": "2024-04-16T16:36:41.574423Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a9b4bc-b18e-483c-9281-7aa1ef01ff1f",
   "metadata": {},
   "source": [
    "### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bfca02e-0ed1-46ca-a0e7-b37b819d7c45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T16:36:50.939685Z",
     "start_time": "2024-04-16T16:36:50.821228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 entries of tagged words:\n",
      "[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS')]\n",
      "\n",
      "\n",
      "10 most common tags in the category 'news':\n",
      "[('NN', 13162), ('IN', 10616), ('AT', 8893), ('NP', 6866), (',', 5133), ('NNS', 5066), ('.', 4452), ('JJ', 4392), ('CC', 2664), ('VBD', 2524)]\n"
     ]
    }
   ],
   "source": [
    "# Get tagged words from the Brown Corpus\n",
    "tagged_words = brown.tagged_words(tagset=None)\n",
    "\n",
    "# List the first 20 entries\n",
    "print(\"First 20 entries of tagged words:\")\n",
    "print(tagged_words[:20])\n",
    "print('\\n')\n",
    "# Get tagged words specifically from the 'news' category\n",
    "tagged_words_news = brown.tagged_words(categories='news', tagset=None)\n",
    "\n",
    "# Calculate frequency distribution of tags in the 'news' category\n",
    "tag_freq_dist = nltk.FreqDist(tag for (word, tag) in tagged_words_news)\n",
    "print(\"10 most common tags in the category 'news':\")\n",
    "print(tag_freq_dist.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02186ccd-c25c-4788-8cd3-d4bc636ad93e",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "\n",
    "In the previous part, you should get ten different POS tags. For each tag, what does it stand for?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc9703d-5e72-40d9-a220-ccd2bac2e5f9",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "\n",
    "```\n",
    "NN  --> singular or mass noun (e.g. car)\n",
    "IN  --> preposition (e.g. at, on)\n",
    "AT  --> article (e.g. a, the)\n",
    "NP  --> proper noun or part of name phrase (e.g. London)\n",
    ",   --> comma \n",
    "NNS --> plural noun (e.g. cars)\n",
    ".   --> sentence closer (e.g. ., !, ?)\n",
    "JJ  --> adjective (e.g. funny)\n",
    "CC  --> coordinating conjunction (e.g. and, or)\n",
    "VBD --> verb, past tense (e.g. took)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e6adb6-1284-4ad3-87b7-b2d3ba5ffbea",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ab5f72-7433-4338-8f7f-2ab002c03074",
   "metadata": {},
   "source": [
    "## Task 2 - POS Tagging (12 P)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c060a2-003d-47a7-a929-e08c940b7389",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "\n",
    "Use a Unigram tagger, trained on the Brown corpus, to tag the example sentence from the Penn treebank (see also https://www.nltk.org/_modules/nltk/corpus/reader/tagged.html)\n",
    "\n",
    "For which words does it completely fail?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65a5acd4-6ab3-494b-a08b-6992b2a0919a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T16:40:02.810919Z",
     "start_time": "2024-04-16T16:40:00.269533Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('treebank')\n",
    "from nltk.corpus import brown, treebank\n",
    "from nltk.tag import UnigramTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d492dec-b7b7-4c86-92e8-f3873221dff3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T16:40:02.817813Z",
     "start_time": "2024-04-16T16:40:02.811937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.', 'Mr.', 'Vinken']\n"
     ]
    }
   ],
   "source": [
    "treebank_test = list(treebank.words()[0:20])\n",
    "print(treebank_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbe059a-1d72-4880-9cfa-0c7c65d8cbe6",
   "metadata": {},
   "source": [
    "### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd7eed60-2a56-4ce9-a0af-cae2eccb987a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T16:40:07.879356Z",
     "start_time": "2024-04-16T16:40:05.218466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pierre -> NP\n",
      "Vinken -> None\n",
      ", -> ,\n",
      "61 -> CD\n",
      "years -> NNS\n",
      "old -> JJ\n",
      ", -> ,\n",
      "will -> MD\n",
      "join -> VB\n",
      "the -> AT\n",
      "board -> NN\n",
      "as -> CS\n",
      "a -> AT\n",
      "nonexecutive -> None\n",
      "director -> NN\n",
      "Nov. -> NP\n",
      "29 -> CD\n",
      ". -> .\n",
      "Mr. -> NP\n",
      "Vinken -> None\n"
     ]
    }
   ],
   "source": [
    "# Train a Unigram tagger on the Brown Corpus\n",
    "unigram_tagger = UnigramTagger(brown.tagged_sents())\n",
    "\n",
    "# Tag the example sentence using the Unigram tagger\n",
    "for word, tag in unigram_tagger.tag(treebank_test):\n",
    "    print(word, '->', tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668b2244-39c2-4139-90c2-f63b8f1004e0",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "\n",
    "The Unigram Tagger completely fails for those words that it has not seen during training (i.e. words that are not in the Brown corpus). In our case, those are the proper noun 'Vinken' and the adjective 'nonexecutive', which both receive the tag 'None'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c49def5-67ab-40e2-a795-28e96acddb1f",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "Compare the tags with the reference tags from the Penn treebank."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8546491-5a53-4ad8-89de-d8e963f69bba",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "170ceed1-3121-4580-b277-223c381167ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pierre', 'NNP'),\n",
       " ('Vinken', 'NNP'),\n",
       " (',', ','),\n",
       " ('61', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('old', 'JJ'),\n",
       " (',', ','),\n",
       " ('will', 'MD'),\n",
       " ('join', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('board', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('nonexecutive', 'JJ'),\n",
       " ('director', 'NN'),\n",
       " ('Nov.', 'NNP'),\n",
       " ('29', 'CD'),\n",
       " ('.', '.'),\n",
       " ('Mr.', 'NNP'),\n",
       " ('Vinken', 'NNP')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treebank.tagged_words()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13abc46-aebe-41d1-ba16-29edc535e942",
   "metadata": {},
   "source": [
    "```\n",
    "Different tags for the same POS: NNP == NP, DT == AT, IN == CS \n",
    "\n",
    "Word         | Treebank | Unigram Tagger | Match\n",
    "-------------------------------------------------\n",
    "Pierre       | NNP      | NP             | 1\n",
    "Vinken       | NNP      | None           | 0\n",
    ",            | ,        | ,              | 1\n",
    "61           | CD       | CD             | 1\n",
    "years        | NNS      | NNS            | 1\n",
    "old          | JJ       | JJ             | 1\n",
    ",            | ,        | ,              | 1\n",
    "will         | MD       | MD             | 1\n",
    "join         | VB       | VB             | 1\n",
    "the          | DT       | AT             | 1\n",
    "board        | NN       | NN             | 1\n",
    "as           | IN       | CS             | 1\n",
    "a            | DT       | AT             | 1\n",
    "nonexecutive | JJ       | None           | 0\n",
    "director     | NN       | NN             | 1\n",
    "Nov.         | NNP      | NP             | 1\n",
    "29           | CD       | CD             | 1\n",
    ".            | .        | .              | 1\n",
    "Mr.          | NNP      | NP             | 1\n",
    "Vinken       | NNP      | None           | 0\n",
    "-------------------------------------------------\n",
    "                                         | 17/20\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9781814-a8ac-4d0f-a884-189cb65492cd",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "\n",
    "Now train \n",
    " 1. a Unigram tagger,\n",
    " 2. a Bigram tagger,\n",
    " 3. and a Brill tagger (using rule brill24)\n",
    " \n",
    "with a subset of the Brown Corpus. This might take 1-2 minutes.\n",
    "\n",
    "Then, validate and compare their performance on a different subset of the Brown corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3f019a5-0973-4268-bc65-e819a1722be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import UnigramTagger, BigramTagger, DefaultTagger\n",
    "from nltk.tag.brill_trainer import BrillTaggerTrainer\n",
    "from nltk.tag.brill import brill24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c764526-7add-4c98-b216-fb57e9a8fb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cutoff = 20000\n",
    "brown_sents_train = brown.tagged_sents()[:n_cutoff] # training corpus\n",
    "brown_sents_test = brown.tagged_sents()[n_cutoff:] # reference corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e6f2de-db09-4ab0-bea7-e9a3469a4e1e",
   "metadata": {},
   "source": [
    "### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c2e1d093-a53c-45dc-b4c5-78b20afb3bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Unigram tagger\n",
    "unigram_tagger = UnigramTagger(brown_sents_train)\n",
    "\n",
    "# Train Bigram tagger\n",
    "bigram_tagger = BigramTagger(brown_sents_train, backoff=unigram_tagger)\n",
    "\n",
    "# Train Brill tagger with DefaultTagger\n",
    "brill_tagger_default = BrillTaggerTrainer(DefaultTagger('NN'), templates=brill24()).train(brown_sents_train)\n",
    "\n",
    "# Train Brill tagger with UnigramTagger\n",
    "brill_tagger_unigram = BrillTaggerTrainer(unigram_tagger, templates=brill24()).train(brown_sents_train)\n",
    "\n",
    "# Train Brill tagger with BrillTagger\n",
    "brill_tagger_bigram = BrillTaggerTrainer(bigram_tagger, templates=brill24()).train(brown_sents_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c9d0ea62-eee4-4a37-bdaf-fb6e4606ecb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Unigram Tagger: 0.8615109858152631\n",
      "Accuracy Bigram Tagger: 0.2070602081522892\n",
      "Accuracy Brill Tagger Default: 0.6558425651587828\n",
      "Accuracy Brill Tagger Unigram: 0.8909027459406198\n",
      "Accuracy Brill Tagger Bigram: 0.727414929213168\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Unigram tagger\n",
    "acc_unigram_tagger = unigram_tagger.accuracy(brown_sents_test)\n",
    "print(\"Accuracy Unigram Tagger:\", acc_unigram_tagger)\n",
    "\n",
    "# Evaluate Bigram tagger\n",
    "acc_bigram_tagger = bigram_tagger.accuracy(brown_sents_test)\n",
    "print(\"Accuracy Bigram Tagger:\", acc_bigram_tagger)\n",
    "\n",
    "# Evaluate Brill tagger with DefaultTagger\n",
    "acc_brill_tagger_default = brill_tagger_default.accuracy(brown_sents_test)\n",
    "print(\"Accuracy Brill Tagger Default:\", acc_brill_tagger_default)\n",
    "\n",
    "# Evaluate Brill tagger with UnigramTagger\n",
    "acc_brill_tagger_unigram = brill_tagger_unigram.accuracy(brown_sents_test)\n",
    "print(\"Accuracy Brill Tagger Unigram:\", acc_brill_tagger_unigram)\n",
    "\n",
    "# Evaluate Brill tagger with BigramTagger\n",
    "acc_brill_tagger_bigram = brill_tagger_bigram.accuracy(brown_sents_test)\n",
    "print(\"Accuracy Brill Tagger Bigram:\", acc_brill_tagger_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b34d750d-02e2-4f53-8c28-de8112f527a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Bigram Tagger Backoff: 0.9403488364136496\n"
     ]
    }
   ],
   "source": [
    "# Train Bigram tagger with Unigram tagger as backoff\n",
    "bigram_tagger_backoff = BigramTagger(brown_sents_train, backoff=unigram_tagger)\n",
    "\n",
    "acc_bigram_tagger_backoff = bigram_tagger_backoff.accuracy(brown_sents_test)\n",
    "print(\"Accuracy Bigram Tagger Backoff:\", acc_bigram_tagger_backoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f97769-7af9-4f27-afab-3353272230de",
   "metadata": {},
   "source": [
    "### Part 4\n",
    "\n",
    "Discuss the scores of your taggers. Which one performs better, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaabf1c-2688-4f23-aa59-1596a46a9e82",
   "metadata": {},
   "source": [
    "### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c0cb08-2647-4f55-948f-a65d4206a801",
   "metadata": {},
   "source": [
    "The performance of the Brill tagger with the highest accuracy among taggers can be attributed to its methodology. It combines statistical probability with rule-based correction. First, the Brill Tagger uses a probabilistic approach, starting from the underlying Unigram Tagger, to create basic tag assignments based on word frequencies. It then refines these using contextual transformation rules. These are designed to capture and correct common tagging errors or ambiguities observed in the training data. This iterative process allows the Brill Tagger to adjust its predictions and ultimately improve its accuracy by utilizing both statistical patterns and linguistic rules.\n",
    "\n",
    "On the other hand, the better performance of the Unigram tagger compared to the Bigram tagger could be due to several factors. First, in certain datasets, single word frequencies (unigrams) may provide more reliable indicators of correct tagging than contextual word pairs (bigrams), especially for sparse data or ambiguous tagging. Secondly, due to its simplicity, the unigram tagger is less prone to overfitting than the bigram tagger, which takes into account the immediate context but may have problems with non-local dependencies or limited training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0627484d-9018-4846-8574-c46ea15f0b67",
   "metadata": {},
   "source": [
    "### Part 5\n",
    "\n",
    "Discuss ideas for improving the implementations and the quality of the taggers. You are not required to implement the improvement ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5a3013-e28e-4acc-a5c3-5e1fd7a80005",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "\n",
    "- Improve by using a larger and more diverse (POS-tagged) training corpus (at least 250.000 words)\n",
    "- Explore N-gram models with higher order (e.g. Trigram ...)\n",
    "- Optimize hyperparameter for each tagger model\n",
    "- Choose more suitable templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aded10e-f01a-44c0-8f78-b9318426fd33",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6f867e-c1f9-4d71-be99-3204b3658f85",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 3 - Unigram and Bigram Taggers (pen and paper) (10 P):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b9b940-bb2a-4e1e-8353-a1bd7d0a736f",
   "metadata": {},
   "source": [
    "**Training data:**\n",
    "\n",
    "His [PRP] raise [NN] was [VB] five [CD] dollars [NN] . [SYM]\n",
    "We [PRP] usually [RB] get [VB] a [DT] raise [NN] at [IN] the [DT] start [NN] of [IN] the [DT] year [NN] . [SYM]\n",
    "A [DT] major [JJ] success [NN] helped [VB] to [TO] raise [VB] our [PRP] spirits [NN] . [SYM]\n",
    "\n",
    "\n",
    "\n",
    "**Test sentence:**\n",
    "\n",
    "It [PRP] looks [VB] like [CC] a [DT] fine [JJ] place [NN] to [TO] raise [NN or VB?] children [NN] . [SYM]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcd51b7-800a-4fc1-a69b-4faa049a82c9",
   "metadata": {},
   "source": [
    "### Part 1: Unigram Tagger\n",
    "\n",
    "Given the training data, determine the most likely tag for the word \"raise\" in the test sentence, using Unigram tagging method:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc77aa4-789e-4483-8656-0a2296e8058a",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "\n",
    "**Naive solution**\n",
    "1. Create a frequency distribution for the different tags in the training data given the word 'raise'\n",
    "2. $p(tag=NN|word=raise) = \\frac{2}{3}, p(tag=VB|word=raise) = \\frac{1}{3}$\n",
    "3. Most likely tag for the word 'raise' is the tag with the greatest frequency in the training data --> tag = NN --> wrong for the test sentence\n",
    "\n",
    "**Consider frequence (Bayes rule), so apply the adapted formula:**\n",
    "$$ P(A|B) = \\frac{P(B|A)P(A)}{P(B)} $$\n",
    "\n",
    "1. $P(B)$ is constant and can be ignored\n",
    "2. Create frequency distributions to apply Bayes rule\n",
    "3. $p(tag=NN|word=raise) = p(word=raise|tag=NN) * p(tag=NN) = \\frac{2}{7} * \\frac{7}{27} \\approx 0.074$\n",
    "$p(tag=VB|word=raise) = p(word=raise|tag=VB) * p(tag=VB) = \\frac{1}{4} * \\frac{4}{27} \\approx 0.037$\n",
    "4. Most likely tag for the word 'raise' is the tag with the greatest frequency in the training data according to Bayes rule --> tag = NN --> wrong for the test sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae00231-a0cd-44c6-97b0-fa444e237d57",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Part 2 - Bigram Tagger:\n",
    "\n",
    "Given the training data (in Task 3), determine the most likely tag for the word \"raise\" in the test sentence, using Bigram tagging method:\n",
    "\n",
    "It [PRP] looks [VB] like [CC] a [DT] fine [JJ] place [NN] to [TO] raise [NN or VB?] children [NN] . [SYM]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aba02ef-c4e1-4ede-aa3a-b03c92aa5f33",
   "metadata": {},
   "source": [
    "1. Create frequency distributions based on the preceding tags of the word 'raise'\n",
    "2. $p(tag=NN|word=raise) = p(tag=NN|prev\\_tag=TO) * p(word=raise|tag=NN) = \\frac{0}{1} * \\frac{2}{7} = 0$\n",
    "$p(tag=VB|word=raise) = p(tab=VB|prev\\_tag=TO) * p(word=raise|tag=VB) = \\frac{1}{1} * \\frac{1}{4} = 0.25$\n",
    "3. Most likely tag for the word 'raise' is the tag with the greatest frequency in the training data according to Bigram tagging method --> tag = VB --> correct for the test sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f649cb9-cd57-43cd-b27c-3cef5fbf9115",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4717fe7-44f7-4446-a698-e3564228a265",
   "metadata": {},
   "source": [
    "#### Submitting your results:\n",
    "\n",
    "To submit your results, please:\n",
    "\n",
    "- save this file, i.e., `ex??_assignment.ipynb`.\n",
    "- if you reference any external files (e.g., images), please create a zip or rar archieve and put the notebook files and all referenced files in there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49b6bc4-1fee-4efe-9a1a-657ec6eab062",
   "metadata": {},
   "source": [
    "**Remarks:**\n",
    "    \n",
    "- Do not copy any code from the Internet. In case you want to use publicly available code, please, add the reference to the respective code snippet.\n",
    "- Check your code compiles and executes, even after you have restarted the Kernel.\n",
    "- Submit your written solutions and the coding exercises within the provided spaces and not otherwise.\n",
    "- Write the names of your partner and your name in the top section."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (NLP)",
   "language": "python",
   "name": "nlp_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
